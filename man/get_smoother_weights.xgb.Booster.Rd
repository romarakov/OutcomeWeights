% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_smoother_weights.R
\name{get_smoother_weights.xgb.Booster}
\alias{get_smoother_weights.xgb.Booster}
\title{Smoother weights for the \code{xgboost::xgb.train} function}
\usage{
\method{get_smoother_weights}{xgb.Booster}(object, X = NULL, Y = NULL, Xnew = NULL, ...)
}
\arguments{
\item{object}{An object of class \code{xgb.Booster}, i.e., the result of
calling \code{xgboost::xgb.train()}.}

\item{X}{Covariate matrix of the training sample.}

\item{Y}{Vector of outcomes of the training sample.}

\item{Xnew}{Optional covariate matrix of the test sample. If \code{NULL},
the smoother matrix for the training data is returned.}

\item{...}{Additional arguments passed to \link{get_smoother_weights}.}
}
\value{
An \eqn{N \times N} smoother matrix.
}
\description{
Post-estimation function to extract smoother weights for an XGBoost model
estimated via the \code{xgb.train} function from the \pkg{xgboost} package.
}
\note{
For smoother extraction, the XGBoost model must be trained with:
\code{alpha = 0}, \code{subsample = 1}, \code{max_delta_step = 0}.
}
\examples{
\dontrun{
set.seed(123)
n <- 100
X <- matrix(rnorm(n * 3), ncol = 3)
Y <- 2 * X[, 1] + 3 * X[, 2] - 1 * X[, 3] + rnorm(n)

# Set the parameters
nrounds <- 100
params <- list(alpha = 0, subsample = 1, max_delta_step = 0)

# Prepare the data
d_train <- xgboost::xgb.DMatrix(data = as.matrix(X), label = Y)
d_test <- xgboost::xgb.DMatrix(data = as.matrix(X))

# Fit XGBoost
object <- xgboost::xgb.train(data = d_train, nrounds = nrounds, params = params)

# Get predictions
preds <- predict(object, newdata = d_test)

# Get smoother matrix
S <- get_smoother_weights(object, X, Y)

# Check equivalence
all.equal(as.numeric(S \%*\% Y), as.numeric(preds))
}

}
